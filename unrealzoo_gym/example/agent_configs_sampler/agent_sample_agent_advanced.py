import numpy as np
from .agent_sample_agent import AgentBasedSampler
import cv2
import os
import svgwrite

class AgentBasedSamplerboost(AgentBasedSampler):
    """å¢å¼ºç‰ˆé‡‡æ ·å™¨ï¼Œæ”¯æŒè‡ªé€‚åº”å‡ ä½•çº¦æŸ"""
    
    def __init__(self, graph_pickle_file, model, config_path="model_config.json"):
        """åˆå§‹åŒ–å¢å¼ºå‹é‡‡æ ·å™¨
        
        Args:
            graph_pickle_file: å›¾çš„pickleæ–‡ä»¶è·¯å¾„
            model: VLMæ¨¡å‹åç§°
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(graph_pickle_file, model, config_path)
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ–°çš„å±æ€§å¦‚æœéœ€è¦
        self.adaptive_mask_params = {}
        self.cam_relative_height = 1200  # é»˜è®¤ç›¸æœºé«˜åº¦ï¼ˆå˜ç±³ï¼‰

    def save_scene_as_svg(self, save_path, background_image_path, W, H):
        """
        å°†ä¸€å¼ å…‰æ …å›¾ç›´æ¥åµŒå…¥åˆ°ä¸€ä¸ª SVG æ–‡ä»¶ä¸­ï¼Œä¸æ·»åŠ ä»»ä½•é¢å¤–å…ƒç´ ã€‚

        Args:
            save_path (str): SVG æ–‡ä»¶ä¿å­˜è·¯å¾„ã€‚
            background_image_path (str): ä½œä¸ºèƒŒæ™¯çš„ PNG/JPG å›¾åƒè·¯å¾„ã€‚
            W (int): å›¾åƒå®½åº¦ã€‚
            H (int): å›¾åƒé«˜åº¦ã€‚
        """
        try:
            dwg = svgwrite.Drawing(save_path, profile='tiny', size=(W, H))
            dwg.add(dwg.image(href=background_image_path, insert=(0, 0), size=(W, H)))
            dwg.save()
            print(f"[Debug] å·²ä¿å­˜ SVG åŒ…è£…: {save_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜ SVG å¤±è´¥: {e}")



    def calculate_collision_radius(self, length, width, yaw_rad):
        """
        åŸºäºç‰©ä½“å°ºå¯¸å’Œæ—‹è½¬ï¼Œè®¡ç®—è¯¥ç‰©ä½“çš„ç¢°æ’åŠå¾„ï¼ˆå¤–æ¥åœ†ï¼‰ã€‚
        
        Args:
            length (float): ç‰©ä½“é•¿åº¦ï¼ˆæ²¿Xè½´ï¼‰
            width (float): ç‰©ä½“å®½åº¦ï¼ˆæ²¿Yè½´ï¼‰
            yaw_rad (float): æ—‹è½¬è§’åº¦ï¼ˆå¼§åº¦ï¼‰
        
        Returns:
            collision_radius (float): æœ€å°å¤–æ¥åœ†åŠå¾„ï¼ˆå˜ç±³ï¼‰
        """
        # è®¡ç®—ç‰©ä½“å››ä¸ªè§’åˆ°ä¸­å¿ƒçš„è·ç¦»
        corners = np.array([
            [length / 2, width / 2],
            [length / 2, -width / 2],
            [-length / 2, width / 2],
            [-length / 2, -width / 2]
        ])
        
        # ä¸ç®¡æ—‹è½¬è§’åº¦å¦‚ä½•ï¼Œå¤–æ¥åœ†åŠå¾„éƒ½æ˜¯å¯¹è§’çº¿é•¿åº¦çš„ä¸€åŠ
        # è¿™æ˜¯å› ä¸ºæ—‹è½¬ä¸æ”¹å˜ç‚¹åˆ°ä¸­å¿ƒçš„è·ç¦»
        diagonal = np.sqrt(length**2 + width**2)
        collision_radius = diagonal / 2.0
        
        return collision_radius
    
    
    def calculate_adaptive_erosion_radius(self, obj_length, obj_width, yaw_rad, 
                                        K, cam_height, safety_margin_cm=50):
        """
        åŸºäºç‰©ä½“å°ºå¯¸ã€æ—‹è½¬å’Œç›¸æœºå‚æ•°ï¼Œè®¡ç®—åœ¨å›¾åƒç©ºé—´ä¸­çš„è‡ªé€‚åº”è…èš€åŠå¾„ã€‚
        
        Args:
            obj_length (float): ç‰©ä½“é•¿åº¦ï¼ˆå˜ç±³ï¼‰
            obj_width (float): ç‰©ä½“å®½åº¦ï¼ˆå˜ç±³ï¼‰
            yaw_rad (float): æ—‹è½¬è§’åº¦ï¼ˆå¼§åº¦ï¼ŒUnrealCVåæ ‡ç³»ï¼‰
            K (np.ndarray): ç›¸æœºå†…å‚çŸ©é˜µ
            cam_height (float): ä¿¯è§†ç›¸æœºé«˜åº¦ï¼ˆå˜ç±³ï¼‰
            safety_margin_cm (float): é¢å¤–çš„å®‰å…¨è¾¹è·ï¼ˆå˜ç±³ï¼‰
        
        Returns:
            erosion_radius_px (int): åœ¨å›¾åƒç©ºé—´ä¸­çš„è…èš€åŠå¾„ï¼ˆåƒç´ ï¼‰
        """
        # 1. è®¡ç®—ç‰©ä½“çš„ç¢°æ’åŠå¾„ï¼ˆå¤–æ¥åœ†ï¼‰
        collision_radius_cm = self.calculate_collision_radius(obj_length, obj_width, yaw_rad)
        
        # 2. åŠ ä¸Šå®‰å…¨è¾¹è·
        total_radius_cm = collision_radius_cm + safety_margin_cm
        
        # 3. å°†å˜ç±³è½¬æ¢ä¸ºå›¾åƒåƒç´ 
        # åœ¨ä¿¯è§†å›¾ä¸­ï¼Œç„¦è·ä¸º fï¼Œé«˜åº¦ä¸º h
        # ç‰©ä½“å¤§å° d_cm åœ¨å›¾åƒä¸­çš„åƒç´ å¤§å°ä¸ºï¼šd_px = f * d_cm / h
        focal_length_px = K[0, 0]
        pixel_per_cm = focal_length_px / cam_height
        erosion_radius_px = int(total_radius_cm * pixel_per_cm)
        
        return erosion_radius_px
         
    def apply_occupied_area_erosion(self, placeable_mask, occupied_area, K, cam_height, 
                                   safety_margin_cm=50):
        """
        é’ˆå¯¹å•ä¸ªå·²æ”¾ç½®çš„ç‰©ä½“ï¼Œå¯¹å¯æ”¾ç½®æ©ç è¿›è¡Œè‡ªé€‚åº”è…èš€ã€‚
        
        Args:
            placeable_mask (np.ndarray): å½“å‰çš„å¯æ”¾ç½®æ©ç 
            occupied_area (dict): å·²æ”¾ç½®ç‰©ä½“çš„å æ®ä¿¡æ¯
                                 {'center_pos': [x, y, z], 'length': int, 'width': int, 
                                  'yaw': float, 'corners': [...]}
            K (np.ndarray): ç›¸æœºå†…å‚çŸ©é˜µ
            cam_height (float): ç›¸æœºé«˜åº¦ï¼ˆå˜ç±³ï¼‰
            safety_margin_cm (float): é¢å¤–å®‰å…¨è¾¹è·ï¼ˆå˜ç±³ï¼‰
        
        Returns:
            updated_mask (np.ndarray): æ›´æ–°åçš„å¯æ”¾ç½®æ©ç 
        """
        import cv2
        
        obj_length = occupied_area['length']
        obj_width = occupied_area['width']
        yaw_deg = occupied_area['yaw']
        yaw_rad = np.radians(yaw_deg)
        center_pos = occupied_area['center_pos']
        
        # 1. è®¡ç®—è¿™ä¸ªç‰©ä½“ç‰¹å®šçš„è…èš€åŠå¾„
        erosion_radius_px = self.calculate_adaptive_erosion_radius(
            obj_length, obj_width, yaw_rad,
            K, cam_height,
            safety_margin_cm=safety_margin_cm
        )
        
        print(f"[OccupiedErosion] ç‰©ä½“åœ¨ {center_pos[:2]} å¤„ï¼Œå°ºå¯¸: {obj_length}x{obj_width}cm, æ—‹è½¬: {yaw_deg:.1f}Â°")
        print(f"[OccupiedErosion] åº”ç”¨è…èš€åŠå¾„: {erosion_radius_px} åƒç´ ")
        
        # 2. åˆ›å»ºæ©ç æ¥æ ‡è®°è¿™ä¸ªç‰©ä½“åŠå…¶å‘¨å›´çš„å®‰å…¨åŒº
        H, W = placeable_mask.shape
        occupied_mask = np.zeros((H, W), dtype=np.uint8)
        
        # å°†ç‰©ä½“çš„å››ä¸ªè§’æŠ•å½±åˆ°å›¾åƒä¸Š
        world_corners = occupied_area['corners']  # shape: (4, 2)
        
        for corner in world_corners:
            corner_3d = np.array([corner[0], corner[1], center_pos[2]])
            u, v, depth = self.world_2_image_unreal(corner_3d, self.cam_pose, K)
            
            if depth > 0 and 0 <= u < W and 0 <= v < H:
                occupied_mask[int(v), int(u)] = 255
        
        # 3. å¯¹ç‰©ä½“å æ®çš„åŒºåŸŸè¿›è¡Œè†¨èƒ€ï¼ˆä»¥æ ‡è®°å æ®åŒºï¼‰
        dilation_kernel = cv2.getStructuringElement(
            cv2.MORPH_ELLIPSE,
            (2 * erosion_radius_px + 1, 2 * erosion_radius_px + 1)
        )
        
        occupied_expanded = cv2.dilate(occupied_mask, dilation_kernel, iterations=1)
        
        # 4. ä»å¯æ”¾ç½®æ©ç ä¸­ç§»é™¤å·²å æ®å’Œå·²è…èš€çš„åŒºåŸŸ
        # occupied_expanded ä¸­çš„åƒç´  > 0 è¡¨ç¤ºä¸å¯æ”¾ç½®
        updated_mask = placeable_mask.copy()
        updated_mask[occupied_expanded > 0] = 0
        
        return updated_mask

    def generate_base_placeable_mask(self, env, cam_id, 
                                normal_variance_threshold=0.05,
                                slope_threshold=0.866,
                                gaussian_kernel_size=5,
                                gaussian_sigma=1.0,
                                W=None, H=None,save_dir="./test_results/"):
        """
        ç”ŸæˆåŸºç¡€å¯æ”¾ç½®æ©ç ï¼ˆå‘é‡åŒ–ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        """
        print("[BasePreprocess] æ­£åœ¨ç”ŸæˆåŸºç¡€å¯æ”¾ç½®æ©ç ...")

        def _save_normal_map(normal_map, filename_prefix):
            """
            è¾…åŠ©å‡½æ•°ï¼Œå¯¹æ³•çº¿å›¾è¿›è¡Œå¯¹æ¯”åº¦å¢å¼ºå¹¶ä¿å­˜ä¸ºå•ä¸ªå½©è‰²å›¾åƒã€‚
            """
            # 1. ç¡®ä¿æˆ‘ä»¬æœ‰ uint8 æ ¼å¼çš„å›¾åƒç”¨äºå¤„ç†
            if normal_map.dtype == np.uint8:
                normal_uint8 = normal_map
            else: 
                # ä» float æ ¼å¼ [-1, 1] è½¬æ¢å› uint8 [0, 255]
                normal_uint8 = (normal_map * 127.0 + 128.0).clip(0, 255).astype(np.uint8)

            # 2. åˆ›å»ºä¸€ä¸ªæ–°çš„ç©ºå›¾åƒç”¨äºå­˜æ”¾å¢å¼ºåçš„ç»“æœ
            enhanced_color = np.zeros_like(normal_uint8)
            
            # 3. å¯¹ R, G, B æ¯ä¸ªé€šé“ç‹¬ç«‹è¿›è¡Œå¯¹æ¯”åº¦æ‹‰ä¼¸
            for i in range(3):
                # cv2.normalize ä¼šæ‰¾åˆ°å½“å‰é€šé“çš„ min/max å€¼ï¼Œå¹¶å°†å…¶æ‹‰ä¼¸åˆ° 0-255
                normalized_channel = cv2.normalize(normal_uint8[:,:,i], None, 0, 255, cv2.NORM_MINMAX)
                enhanced_color[:,:,i] = normalized_channel
            
            # 4. è½¬æ¢é¢œè‰²ç©ºé—´å¹¶ä¿å­˜
            enhanced_color_bgr = cv2.cvtColor(enhanced_color, cv2.COLOR_RGB2BGR)
            filepath = os.path.join(save_dir, f"{filename_prefix}_enhanced.png")
            cv2.imwrite(filepath, enhanced_color_bgr)
            print(f"[Debug] å·²ä¿å­˜å¯¹æ¯”åº¦å¢å¼ºæ³•çº¿å›¾: {filepath}")



        # 1. è·å–æ³•çº¿å›¾
        normal_bgr = env.unrealcv.read_image(cam_id, 'normal')
        normal_rgb = cv2.cvtColor(normal_bgr, cv2.COLOR_BGR2RGB)
        _save_normal_map(normal_rgb, "debug_normal_01_raw.png")

        if W is None or H is None:
            H, W = normal_rgb.shape[:2]
        
        print(f"[BasePreprocess] æ³•çº¿å›¾å½¢çŠ¶: {normal_rgb.shape}")
        
        # 2. æ³•çº¿è§£ç  + å½’ä¸€åŒ–
        normal_float = (normal_rgb.astype(np.float32) - 128.0) / 127.0
        normal_length = np.linalg.norm(normal_float, axis=2, keepdims=True)
        normal_normalized = np.divide(
            normal_float, 
            normal_length, 
            out=np.zeros_like(normal_float),
            where=normal_length > 0.1
        )
        _save_normal_map(normal_normalized, "debug_normal_02_normalized.png")
        # 3. é«˜æ–¯å¹³æ»‘
        print("[BasePreprocess] åº”ç”¨é«˜æ–¯å¹³æ»‘...")
        normal_smoothed = cv2.GaussianBlur(
            normal_normalized, 
            (gaussian_kernel_size, gaussian_kernel_size), 
            gaussian_sigma
        )
        _save_normal_map(normal_smoothed, "debug_normal_03_smoothed.png")
        # 4. é‡æ–°å½’ä¸€åŒ–
        normal_smoothed_length = np.linalg.norm(normal_smoothed, axis=2, keepdims=True)
        final_normal_map = np.divide(
            normal_smoothed,
            normal_smoothed_length,
            out=np.zeros_like(normal_smoothed),
            where=normal_smoothed_length > 0.1
        )
        _save_normal_map(final_normal_map, "debug_normal_04_final.png")
        # ========================================
        # === ğŸš€ å…³é”®ä¼˜åŒ–ï¼šå‘é‡åŒ–è®¡ç®—å¹³æ»‘åº¦ ===
        # ========================================
        print("[BasePreprocess] è®¡ç®—å¹³æ»‘åº¦æ©ç ï¼ˆå‘é‡åŒ–ç‰ˆæœ¬ï¼‰...")
        
        kernel_size = 5
        pad_size = kernel_size // 2
        
        # ä½¿ç”¨ cv2.boxFilter è®¡ç®—å±€éƒ¨å‡å€¼ï¼ˆè¶…å¿«ï¼ï¼‰
        mean_normal = cv2.boxFilter(
            final_normal_map, 
            ddepth=-1, 
            ksize=(kernel_size, kernel_size),
            normalize=True,
            borderType=cv2.BORDER_REPLICATE
        )
        
        # å½’ä¸€åŒ–å‡å€¼æ³•çº¿
        mean_normal_length = np.linalg.norm(mean_normal, axis=2, keepdims=True)
        mean_normal_normalized = np.divide(
            mean_normal,
            mean_normal_length,
            out=np.zeros_like(mean_normal),
            where=mean_normal_length > 1e-6
        )
        
        # ä½¿ç”¨ uniform_filter è®¡ç®—å±€éƒ¨æ–¹å·®ï¼ˆå‘é‡åŒ–ï¼‰
        from scipy.ndimage import uniform_filter
        
        # è®¡ç®—æ¯ä¸ªåƒç´ ä¸å…¶å±€éƒ¨å‡å€¼æ³•çº¿çš„ç‚¹ç§¯
        dot_product = np.sum(final_normal_map * mean_normal_normalized, axis=2)
        dot_product = np.clip(dot_product, -1.0, 1.0)
        
        # è§’åº¦
        angles = np.arccos(dot_product)
        
        # è®¡ç®—å±€éƒ¨æ–¹å·®ï¼ˆä½¿ç”¨ Var(X) = E[XÂ²] - E[X]Â² ï¼‰
        angles_squared = angles ** 2
        local_mean_sq = uniform_filter(angles_squared, size=kernel_size, mode='nearest')
        local_mean = uniform_filter(angles, size=kernel_size, mode='nearest')
        smooth_map = local_mean_sq - local_mean ** 2
        
        # å¤„ç†æ— æ•ˆåŒºåŸŸ
        smooth_map[mean_normal_length[:, :, 0] < 1e-6] = 255
        
        smooth_mask = (smooth_map < normal_variance_threshold).astype(np.uint8) * 255
        print(f"[BasePreprocess] å¹³æ»‘åŒºåŸŸå æ¯”: {(smooth_map < normal_variance_threshold).sum() / (H * W) * 100:.2f}%")
        
        # ========================================
        
        # 6. è®¡ç®—å¡åº¦æ©ç ï¼ˆå·²ç»æ˜¯å‘é‡åŒ–çš„ï¼‰
        print("[BasePreprocess] è®¡ç®—å¡åº¦æ©ç ...")
        vertical_direction = np.array([0.0, 0.0, 1.0])
        dot_product = np.dot(final_normal_map, vertical_direction)
        slope_mask = (dot_product > slope_threshold).astype(np.uint8) * 255
        print(f"[BasePreprocess] ä¸é™¡å³­åŒºåŸŸå æ¯”: {(dot_product > slope_threshold).sum() / (H * W) * 100:.2f}%")
        
        # 7. åˆå¹¶åŸºç¡€æ©ç 
        base_mask = cv2.bitwise_and(smooth_mask, slope_mask)
        print(f"[BasePreprocess] åŸºç¡€æ©ç å®Œæˆï¼Œå¯æ”¾ç½®åŒºåŸŸ: {(base_mask > 0).sum() / (H * W) * 100:.2f}%")
        
        self.visualize_mask(smooth_mask, "debug_mask_01_smooth.png", save_dir)
        self.visualize_mask(slope_mask, "debug_mask_02_slope.png", save_dir)
        self.visualize_mask(base_mask, "debug_mask_03_base_placeable.png", save_dir)
        
        # # å¯é€‰ï¼šå åŠ åœ¨åŸå§‹ä¿¯è§†å›¾ä¸Š
        # self.overlay_mask_on_image(obs_rgb, base_mask, alpha=0.4, 
        #                            filename="debug_mask_04_overlay_on_topview.png", 
        #                            save_dir=save_dir)  


        return base_mask, final_normal_map, (W, H)

    def apply_adaptive_erosion_to_mask(self, base_mask, next_object_info, 
                                   safety_margin_cm=50):
        """
        å¯¹åŸºç¡€æ©ç åº”ç”¨ç‰©ä½“ç‰¹å®šçš„è‡ªé€‚åº”è…èš€ï¼ˆå¿«é€Ÿç‰ˆæœ¬ï¼‰
        
        Args:
            base_mask: åŸºç¡€å¯æ”¾ç½®æ©ç 
            next_object_info: å¾…æ”¾ç½®ç‰©ä½“çš„ä¿¡æ¯
            safety_margin_cm: å®‰å…¨è¾¹è·
        
        Returns:
            adaptive_mask: åº”ç”¨è…èš€åçš„æ©ç 
            erosion_radius: è…èš€åŠå¾„ï¼ˆåƒç´ ï¼‰
        """
        obj_length = next_object_info.get('length', 100)
        obj_width = next_object_info.get('width', 100)
        rotation = next_object_info.get('rotation', [0, 0, 0])
        yaw_deg = rotation[1] if len(rotation) > 1 else 0
        yaw_rad = np.radians(yaw_deg)
        

        
        # è®¡ç®—è…èš€åŠå¾„
        erosion_radius_px = self.calculate_adaptive_erosion_radius(
            obj_length, obj_width, yaw_rad, self.K, self.cam_relative_height,
            safety_margin_cm=safety_margin_cm
        )
        
        # åº”ç”¨è…èš€
        erosion_kernel = cv2.getStructuringElement(
            cv2.MORPH_ELLIPSE,
            (2 * erosion_radius_px + 1, 2 * erosion_radius_px + 1)
        )
        
        adaptive_mask = cv2.erode(base_mask, erosion_kernel, iterations=1)
        
        return adaptive_mask, erosion_radius_px

    def visualize_mask(self, mask, filename, save_dir="./test_results/", colormap=cv2.COLORMAP_JET):
        """
        å¯è§†åŒ–æ©ç ä¸ºå½©è‰²å›¾åƒå¹¶ä¿å­˜ã€‚
        
        Args:
            mask (np.ndarray): äºŒå€¼æˆ–ç°åº¦æ©ç  (H, W)
            filename (str): ä¿å­˜çš„æ–‡ä»¶å
            save_dir (str): ä¿å­˜ç›®å½•
            colormap: OpenCV çš„è‰²å½©æ˜ å°„æ–¹æ¡ˆ
        
        Returns:
            colored_mask (np.ndarray): å½©è‰²åŒ–åçš„æ©ç 
        """
        os.makedirs(save_dir, exist_ok=True)
        
        # ç¡®ä¿æ©ç æ˜¯ uint8 æ ¼å¼
        if mask.dtype != np.uint8:
            mask_uint8 = (mask * 255).astype(np.uint8) if mask.max() <= 1.0 else mask.astype(np.uint8)
        else:
            mask_uint8 = mask
        
        # åº”ç”¨è‰²å½©æ˜ å°„
        colored_mask = cv2.applyColorMap(mask_uint8, colormap)
        
        # ä¿å­˜
        filepath = os.path.join(save_dir, filename)
        cv2.imwrite(filepath, colored_mask)
        print(f"[Visualization] å·²ä¿å­˜æ©ç å¯è§†åŒ–: {filepath}")
        
        return colored_mask

    def overlay_mask_on_image(self, image, mask, alpha=0.5, filename=None, save_dir="./test_results/"):
        """
        å°†æ©ç å åŠ åœ¨åŸå§‹å›¾åƒä¸Šï¼Œç”¨äºå¯è§†åŒ–æ•ˆæœã€‚
        
        Args:
            image (np.ndarray): åŸå§‹RGBå›¾åƒ (H, W, 3)
            mask (np.ndarray): äºŒå€¼æ©ç  (H, W)
            alpha (float): æ©ç çš„é€æ˜åº¦ (0-1)
            filename (str): ä¿å­˜æ–‡ä»¶å (å¯é€‰)
            save_dir (str): ä¿å­˜ç›®å½•
        
        Returns:
            overlayed (np.ndarray): å åŠ åçš„RGBå›¾åƒ
        """
        os.makedirs(save_dir, exist_ok=True)
        
        # ç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´
        image = image.astype(np.float32)
        mask = mask.astype(np.float32) / 255.0 if mask.max() > 1.0 else mask.astype(np.float32)
        
        # åˆ›å»ºå½©è‰²æ©ç ï¼ˆç»¿è‰²è¡¨ç¤ºå¯æ”¾ç½®åŒºåŸŸï¼‰
        colored_mask = np.zeros_like(image)
        colored_mask[:, :, 1] = mask * 255  # ç»¿è‰²é€šé“
        
        # å åŠ 
        overlayed = (image * (1 - alpha) + colored_mask * alpha).astype(np.uint8)
        
        if filename:
            filepath = os.path.join(save_dir, filename)
            overlayed_bgr = cv2.cvtColor(overlayed, cv2.COLOR_RGB2BGR)
            cv2.imwrite(filepath, overlayed_bgr)
            print(f"[Visualization] å·²ä¿å­˜å åŠ å›¾åƒ: {filepath}")
        
        return overlayed

    def run_sampling_experiment(self, env, agent_configs, experiment_config, cam_id=0, 
                               cam_count=3, vehicle_zones=None, height=800, **kwargs):
        """
        ä¼˜åŒ–ç‰ˆæœ¬ï¼šé¢„å¤„ç†åŸºç¡€æ©ç  + å¾ªç¯å†…è‡ªé€‚åº”è…èš€
        """
        # 1-4. ä¿æŒåŸæœ‰é€»è¾‘...
        save_dir = kwargs.get('save_dir', './test_results/')
        os.makedirs(save_dir, exist_ok=True)
        object_list, all_objects_are_small, has_car = self.sort_objects(agent_configs)
        vehicle_zone_nodes = self.filter_car_zones(vehicle_zones)
        agent_sampling_center_pos, center_node = self.sample_center_point(vehicle_zone_nodes, has_car, all_objects_are_small)
        
        self.ground_z = agent_sampling_center_pos[2]
        orginal_cam_pose = env.unrealcv.get_cam_location(cam_id) + env.unrealcv.get_cam_rotation(cam_id)
        
        if agent_sampling_center_pos is not None:
            env.unrealcv.set_cam_location(cam_id, np.append(agent_sampling_center_pos[:2], agent_sampling_center_pos[2] + height))
            env.unrealcv.set_cam_rotation(cam_id, [-90, 0, 0])
        self.cam_relative_height = height
        obs_bgr = env.unrealcv.read_image(cam_id, 'lit')
        obs_rgb = cv2.cvtColor(obs_bgr, cv2.COLOR_BGR2RGB)
        cv2.imwrite(f"{save_dir}/debug_topdown_view.png", obs_bgr)
        # self.save_scene_as_svg(
        #     save_path=f"{save_dir}/debug_sampling_step_{i+1}.svg",
        #     background_image_path=png_path,
        #     W=self.W, H=self.H
        # )
        cam_location = env.unrealcv.get_cam_location(cam_id)
        cam_rotation = env.unrealcv.get_cam_rotation(cam_id)
        self.cam_pose = cam_location + cam_rotation
        self.W, self.H = obs_rgb.shape[1], obs_rgb.shape[0]
        self.fov_deg = float(env.unrealcv.get_cam_fov(cam_id))
        self.K = self.get_camera_matrix_unreal(self.W, self.H, self.fov_deg)
        
        img_points, valid_mask, depths = self.project_points_to_image_unreal(
            self.node_list, self.cam_pose, self.W, self.H, self.fov_deg
        )
        
        all_valid_points_dict = {}
        for i, (node, node_id, valid) in enumerate(zip(self.node_list, self.node_id_list, valid_mask)):
            if valid:
                all_valid_points_dict[tuple(node)] = {'index': i, 'node': node_id}

        result_img = self.visualize_projected_points_unreal_with_next_object(
                obs_rgb, img_points, valid_mask , depths, self.W, self.H)
        result_img_bgr = cv2.cvtColor(result_img, cv2.COLOR_RGB2BGR)
        cv2.imwrite(f"{save_dir}/debug_initial_projection.png", result_img_bgr)
        
        # ========================================
        # === ğŸš€ å…³é”®ä¼˜åŒ–ï¼šé¢„å¤„ç†åŸºç¡€æ©ç ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰ ===
        # ========================================
        print("\n" + "="*60)
        print("ğŸš€ å¼€å§‹é¢„å¤„ç†åŸºç¡€å¯æ”¾ç½®æ©ç ï¼ˆæ‰§è¡Œ1æ¬¡ï¼‰...")
        print("="*60)
        
        base_placeable_mask, final_normal_map, (W, H) = self.generate_base_placeable_mask(
            env=env,
            cam_id=cam_id,
            normal_variance_threshold=kwargs.get('normal_variance_threshold', 0.05),
            slope_threshold=kwargs.get('slope_threshold', 0.866),
            W=self.W,
            H=self.H,
            save_dir=save_dir,
            gaussian_kernel_size=kwargs.get('gaussian_kernel_size', 5),
            gaussian_sigma=kwargs.get('gaussian_sigma', 1.0)
        )
        
        print("âœ… åŸºç¡€æ©ç é¢„å¤„ç†å®Œæˆï¼\n")
        
        # === ä¸»é‡‡æ ·å¾ªç¯ ===
        sampled_objects = []
        occupied_areas = []
        pending_objects = []
        
        for obj_info in object_list:
            agent_type, _, _, name, _, _, _, _ = obj_info
            yaw = self._determine_object_orientation(agent_type)
            pending_objects.append({'name': name, 'rotation': [0, yaw, 0]})
        
        for i, obj_info in enumerate(object_list):
            agent_type, length, width, name, app_id, animation, feature_caption, type_val = obj_info
            current_obj_details = {
                'name': name, 'length': length, 'width': width, 'agent_type': agent_type,
                'rotation': pending_objects[i]['rotation']
            }
            yaw = current_obj_details['rotation'][1]
            
            # ========================================
            # === ğŸš€ ä¼˜åŒ–ï¼šå¿«é€Ÿåº”ç”¨è‡ªé€‚åº”è…èš€ ===
            # ========================================
            print(f"\n[Sampling] ç‰©ä½“ {i+1}/{len(object_list)} ({name}): åº”ç”¨è‡ªé€‚åº”è…èš€...")

            # ä»åŸºç¡€æ©ç å¼€å§‹
            adaptive_mask = base_placeable_mask.copy()
          
            # åº”ç”¨ç‰©ä½“ç‰¹å®šçš„è…èš€
            adaptive_mask, erosion_radius = self.apply_adaptive_erosion_to_mask(
                adaptive_mask,
                current_obj_details,
                safety_margin_cm=kwargs.get('safety_margin_cm', 50)
            )
            self.visualize_mask(adaptive_mask, f"debug_step_{i+1}_a_base_mask.png", save_dir)

            print(f"[Sampling] ç‰©ä½“è…èš€åŠå¾„: {erosion_radius}px")
            
            # å¯¹æ‰€æœ‰å·²æ”¾ç½®çš„ç‰©ä½“åº”ç”¨è…èš€
            for j, occ_area in enumerate(occupied_areas):
                adaptive_mask = self.apply_occupied_area_erosion(
                    adaptive_mask, occ_area, self.K, self.cam_relative_height,
                    safety_margin_cm=kwargs.get('safety_margin_cm', 50)
                )
            
            print(f"[Sampling] æœ€ç»ˆå¯æ”¾ç½®åŒºåŸŸ: {(adaptive_mask > 0).sum() / (H * W) * 100:.2f}%")
            self.visualize_mask(adaptive_mask, f"debug_step_{i+1}_d_final_adaptive_mask.png", save_dir)
            
            # å åŠ åœ¨ä¿¯è§†å›¾ä¸ŠæŸ¥çœ‹æ•ˆæœ
            self.overlay_mask_on_image(obs_rgb, adaptive_mask, alpha=0.5,
                                       filename=f"debug_step_{i+1}_e_final_adaptive_overlay.png",
                                       save_dir=save_dir)
                    
            
            # ä½¿ç”¨è‡ªé€‚åº”æ©ç ç­›é€‰æœ‰æ•ˆç‚¹
            geometry_filtered_mask = self.filter_valid_points_by_placeable_mask(
                img_points, valid_mask, adaptive_mask, margin_pixels=10
            )
            
            updated_valid_points_dict = {}  # ä¸–ç•Œåæ ‡ -> {index, node}
            node_to_world_map = {}          # å›¾èŠ‚ç‚¹ -> ä¸–ç•Œåæ ‡
            
            for j, (node, node_id, geom_valid) in enumerate(zip(
                self.node_list, self.node_id_list, geometry_filtered_mask
            )):
                if geom_valid:
                    world_pos = tuple(node)  # ä¸–ç•Œåæ ‡ (x, y, z)
                    updated_valid_points_dict[world_pos] = {'index': j, 'node': node_id}
                    node_to_world_map[node_id] = world_pos  # åå‘æ˜ å°„
            
            print(f"[Sampling] ç‰©ä½“ {name}: åˆå§‹ {valid_mask.sum()} -> å‡ ä½•ç­›é€‰å {geometry_filtered_mask.sum()}")
            # geom_filtered_mask_uint8 = geometry_filtered_mask.astype(np.uint8) * 255
            # self.visualize_mask(geom_filtered_mask_uint8, f"debug_step_{i+1}_f_geometry_filtered_mask.png", save_dir)
            
            # å¯è§†åŒ–
            result_img = self.visualize_projected_points_unreal_with_next_object(
                obs_rgb, img_points, geometry_filtered_mask, depths, self.W, self.H,
                occupied_areas, current_obj_details
            )
            result_img_no_next_obj = self.visualize_projected_points_unreal_with_next_object(
                obs_rgb, img_points, geometry_filtered_mask, depths, self.W, self.H,
                occupied_areas
            )
            result_img_no_next_obj_bgr = cv2.cvtColor(result_img_no_next_obj, cv2.COLOR_RGB2BGR)
            cv2.imwrite(f"{save_dir}/debug_sampling_step_{i+1}_no_next_obj.png", result_img_no_next_obj_bgr)
            print(f"[Debug] å·²ä¿å­˜å¯è§†åŒ–: {save_dir}/debug_sampling_step_{i+1}.png")

            # æ ¹æ®æ¨¡å¼é€‰æ‹©ç‚¹
            use_fast_mode = kwargs.get('fast_test_mode', False)
            
            if use_fast_mode:
                # å¿«é€Ÿæ¨¡å¼ï¼šéšæœºé€‰ç‚¹ï¼ˆä»ä¸–ç•Œåæ ‡ä¸­é€‰ï¼‰
                if len(updated_valid_points_dict) == 0:
                    print(f"âš ï¸  è­¦å‘Šï¼šç‰©ä½“ {name} æ²¡æœ‰å¯ç”¨ç‚¹ï¼Œè·³è¿‡ã€‚")
                    current_node_to_try = None
                else:
                    import random
                    world_pos = random.choice(list(updated_valid_points_dict.keys()))
                    node_id = updated_valid_points_dict[world_pos]['node']
                    print(f"âœ… [FastMode] éšæœºé€‰æ‹©ç‚¹: Node {node_id} at {world_pos}")
                    current_node_to_try = node_id  # â† ä½¿ç”¨ä¸–ç•Œåæ ‡
            else:
                # ===== ğŸš€ æ ‡å‡†æ¨¡å¼ï¼šVLMé€‰ç‚¹ï¼ˆéœ€è¦è½¬æ¢ï¼‰ =====
                selected_node_id = self.sample_object_points(
                    result_img, name, length, width, updated_valid_points_dict, 
                    experiment_config
                )
                
                if selected_node_id is None:
                    print(f"âš ï¸  è­¦å‘Šï¼šVLMæœªè¿”å›æœ‰æ•ˆèŠ‚ç‚¹ï¼Œè·³è¿‡ç‰©ä½“ {name}")
                    current_node_to_try = None
                elif selected_node_id in node_to_world_map:
                    # å…³é”®ï¼šå°†å›¾èŠ‚ç‚¹è½¬æ¢ä¸ºä¸–ç•Œåæ ‡
                    current_node_to_try = selected_node_id
                    current_node_coord = node_to_world_map[selected_node_id]
                    print(f"âœ… [VLM] é€‰æ‹©ç‚¹: Node {selected_node_id} -> World {current_node_coord}")
                else:
                    print(f"âš ï¸  é”™è¯¯ï¼šVLMè¿”å›çš„èŠ‚ç‚¹ {selected_node_id} ä¸åœ¨æœ‰æ•ˆç‚¹é›†åˆä¸­")
                    current_node_to_try = None

            if current_node_to_try is None:
                print(f"è­¦å‘Šï¼šä¸ºç‰©ä½“ {name} é‡‡æ ·ä½ç½®å¤±è´¥ï¼Œè·³è¿‡æ­¤ç‰©ä½“ã€‚")
                continue
            
            position = self.node_positions[current_node_to_try]
            
            object_dict = {
                'node': current_node_to_try, 'position': position, 
                'rotation': current_obj_details['rotation'],
                'agent_type': agent_type, 'type': type_val, 'name': name, 
                'app_id': app_id, 'animation': animation, 
                'feature_caption': feature_caption, 'dimensions': (length, width)
            }
            sampled_objects.append(object_dict)
            
            # æ›´æ–°æœ‰æ•ˆç‚¹æ©ç 
            valid_mask = self._mark_area_occupied(
                current_node_to_try, occupied_areas, valid_mask, length, width, yaw
            )
            
            # å¯è§†åŒ–ï¼šæ›´æ–°åçš„æœ‰æ•ˆç‚¹æ©ç ï¼ˆç”¨äºä¸‹ä¸€æ¬¡è¿­ä»£ï¼‰
            # valid_mask_uint8 = valid_mask.astype(np.uint8) * 255
            # self.visualize_mask(valid_mask_uint8, f"debug_step_{i+1}_i_updated_valid_mask_for_next.png", save_dir)
            
            all_valid_points_dict = {}
            for j, (node, node_id, valid) in enumerate(zip(self.node_list, self.node_id_list, valid_mask)):
                if valid:
                    all_valid_points_dict[tuple(node)] = {'index': j, 'node': node_id}
        
        # 5-10. ç›¸æœºé‡‡æ ·å’Œè¿”å›ï¼ˆä¿æŒä¸å˜ï¼‰...
        cameras = self._sample_external_cameras(
            objects=sampled_objects,
            camera_count=cam_count,
            ring_inner_radius_offset=kwargs.get('ring_inner_radius_offset', 200),
            ring_outer_radius_offset=kwargs.get('ring_outer_radius_offset', 800),
            min_angle_separation_deg=kwargs.get('min_angle_separation_deg', 30),
            min_cam_to_agent_dist=kwargs.get('min_cam_to_agent_dist', 150)
        )
        
        result_img_with_cams = self.visualize_projected_points_unreal_with_cameras(
            obs_rgb, img_points, valid_mask, depths, self.W, self.H,
            occupied_areas, cameras
        )
        result_img_rgb = cv2.cvtColor(result_img_with_cams, cv2.COLOR_RGB2BGR)
        cv2.imwrite(f"{save_dir}/debug_sampling_step_with_cameras_optimized.png", result_img_rgb)
        
        camera_id_list = self.sample_camera_points(result_img_rgb)
        
        selected_cameras = []
        if camera_id_list:
            for cam_info in cameras:
                if cam_info["id"] in camera_id_list:
                    selected_cameras.append(cam_info)
        
        updated_configs, camera_configs = self.format_transform(agent_configs, sampled_objects, selected_cameras)
        center_pos_to_return = agent_sampling_center_pos.tolist() if isinstance(agent_sampling_center_pos, np.ndarray) else agent_sampling_center_pos
        all_distances = [np.linalg.norm(np.array(obj['position']) - agent_sampling_center_pos) for obj in sampled_objects]
        agent_sampling_radius = max(all_distances) + 200 if all_distances else 200
        
        env.unrealcv.set_cam_location(cam_id, orginal_cam_pose[:3])
        env.unrealcv.set_cam_rotation(cam_id, orginal_cam_pose[3:])
        
        return {
            "env": env,
            'agent_configs': updated_configs,
            'camera_configs': camera_configs,
            'sampling_center': center_pos_to_return,
            'sampling_radius': agent_sampling_radius
        }

    def sample_agent_positions(self, env, agent_configs, cam_id=0, cam_count=3, 
                                vehicle_zones=None, all_max_distance=None,
                                ring_inner_radius_offset=300,
                                ring_outer_radius_offset=500,
                                min_angle_separation_deg=35,
                                min_cam_to_agent_dist=200,
                                height=800, **kwargs):
            """
            å…¼å®¹åŸæ–¹æ³•çš„åŒ…è£…å™¨ã€‚è‡ªåŠ¨è°ƒç”¨æ–°çš„è‡ªé€‚åº”é‡‡æ ·æ–¹æ³•ã€‚
            
            Args:
                env: ç¯å¢ƒå®ä¾‹
                agent_configs: æ™ºèƒ½ä½“é…ç½®
                cam_id: ç›¸æœºID
                cam_count: ç›¸æœºæ•°é‡
                vehicle_zones: è½¦è¾†åŒºåŸŸ
                all_max_distance: æœ€å¤§è·ç¦»
                ring_inner_radius_offset: ç¯å†…åŠå¾„åç§»
                ring_outer_radius_offset: ç¯å¤–åŠå¾„åç§»
                min_angle_separation_deg: æœ€å°è§’åº¦åˆ†ç¦»
                min_cam_to_agent_dist: æœ€å°ç›¸æœºåˆ°æ™ºèƒ½ä½“è·ç¦»
                height: ç›¸æœºé«˜åº¦
                **kwargs: å…¶ä»–å‚æ•°
            
            Returns:
                dict: é‡‡æ ·ç»“æœ
            """
            print("[å…¼å®¹æ€§åŒ…è£…å™¨] è°ƒç”¨è‡ªé€‚åº”é‡‡æ ·æ–¹æ³•...")
            
            # ç›´æ¥è°ƒç”¨æ–°æ–¹æ³•
            result = self.run_sampling_experiment(
                env=env,
                agent_configs=agent_configs,
                experiment_config={'type': 'data_generation'},
                cam_id=cam_id,
                cam_count=cam_count,
                vehicle_zones=vehicle_zones,
                height=height,
                ring_inner_radius_offset=ring_inner_radius_offset,
                ring_outer_radius_offset=ring_outer_radius_offset,
                min_angle_separation_deg=min_angle_separation_deg,
                min_cam_to_agent_dist=min_cam_to_agent_dist,
                **kwargs
            )
            
            return result


    
    def filter_valid_points_by_placeable_mask(self, img_points, valid_mask, placeable_mask, 
                                             margin_pixels=5):
        """
        ä½¿ç”¨å¯æ”¾ç½®æ©ç è¿›ä¸€æ­¥ç­›é€‰æœ‰æ•ˆç‚¹ã€‚
        """
        H, W = placeable_mask.shape
        refined_mask = valid_mask.copy()
        
        for idx, (point, is_valid) in enumerate(zip(img_points, valid_mask)):
            if not is_valid:
                continue
            
            u, v = int(point[0]), int(point[1])
            
            if (margin_pixels <= u < W - margin_pixels and 
                margin_pixels <= v < H - margin_pixels):
                if placeable_mask[v, u] == 0:
                    refined_mask[idx] = False
            else:
                refined_mask[idx] = False
        
        print(f"[GeometryFilter] å‡ ä½•ç­›é€‰åï¼Œæœ‰æ•ˆç‚¹æ•°: {refined_mask.sum()} / {len(refined_mask)}")
        return refined_mask